import os
import numpy as np
from keras import Input, models
from keras.layers import LSTM, Dense
from keras.models import Sequential
from keras.utils import plot_model, to_categorical
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Define the model architecture function
def build_model(input_shape, num_classes):
    model = Sequential()
    model.add(Input(shape=input_shape))  # e.g., (10, 1)
    model.add(LSTM(10, return_sequences=True))
    model.add(LSTM(10, return_sequences=False))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# Define your metric estimation function (example, adapt as needed)
def main_est_parameters(y_true, y_pred):
    # Example returns accuracy and classification report dictionary
    accuracy = np.mean(y_true == y_pred)
    report = classification_report(y_true, y_pred, output_dict=True)
    return {'accuracy': accuracy, 'classification_report': report}

# Complete training function
def proposed_model(x_train, x_test, y_train, y_test, train_percent, DB, epochs_list=[1, 200, 300, 400, 500]):
    input_shape = x_train.shape[1:]  # Example: (10,1)
    num_classes = len(np.unique(y_train))

    # One-hot encode the labels
    y_train_cat = to_categorical(y_train, num_classes)
    y_test_cat = to_categorical(y_test, num_classes)

    # Build model
    model = build_model(input_shape, num_classes)
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    # Create directories if not exist
    checkpoint_dir = f"Checkpoint/{DB}/TP_{int(train_percent * 100)}"
    os.makedirs(checkpoint_dir, exist_ok=True)
    metric_path = f"Analysis/Performance_Analysis/With_Smote/{DB}/"
    os.makedirs(metric_path, exist_ok=True)
    os.makedirs("Architectures/", exist_ok=True)
    os.makedirs("Saved_model/", exist_ok=True)

    prev_epoch = 0
    # Load latest checkpoint if exists
    for ep in reversed(epochs_list):
        checkpoint_path = os.path.join(checkpoint_dir, f"model_epoch_{ep}.weights.h5")
        metrics_file = os.path.join(metric_path, f"metrics_{train_percent}percent_epoch{ep}.npy")
        if os.path.exists(checkpoint_path) and os.path.exists(metrics_file):
            print(f"Found existing checkpoint and metrics for epoch {ep}, loading model...")
            model.load_weights(checkpoint_path)
            prev_epoch = ep
            break

    metrics_all = {}
    for end_epoch in epochs_list:
        if end_epoch <= prev_epoch:
            continue
        print(f"Training from epoch {prev_epoch+1} to {end_epoch} for TP={train_percent*100}%...")

        checkpoint_path = os.path.join(checkpoint_dir, f"model_epoch_{end_epoch}.weights.h5")
        metrics_file = os.path.join(metric_path, f"metrics_{train_percent}percent_epoch{end_epoch}.npy")

        try:
            model.fit(x_train, y_train_cat,
                      epochs=end_epoch,
                      initial_epoch=prev_epoch,
                      batch_size=8,
                      validation_split=0.2,
                      verbose=2)

            # Save the model architecture visualization
            plot_model(model, to_file="Architectures/model_architecture.png", show_shapes=True, show_layer_names=True)

            # Save model and weights
            model.save(f"Saved_model/{DB}_model.h5")
            model.save_weights(checkpoint_path)
            print(f"Checkpoint saved at: {checkpoint_path}")

            # Predict and calculate metrics
            preds = model.predict(x_test)
            y_pred = np.argmax(preds, axis=1)
            y_test_labels = np.argmax(y_test_cat, axis=1)
            metrics = main_est_parameters(y_test_labels, y_pred)

            metrics_all[f"epoch_{end_epoch}"] = metrics
            np.save(metrics_file, metrics)
            print(f"Metrics saved at: {metrics_file}")

            prev_epoch = end_epoch

            # Save model in additional format if needed
            model.save(f"Saved_model/{DB}_model.keras")

        except KeyboardInterrupt:
            print(f"Training interrupted during epochs {prev_epoch+1} to {end_epoch}. Not saving checkpoint or metrics.")
            raise

        print(f"Completed training for {train_percent*100}% data up to epoch {prev_epoch}.")

    return metrics_all


# Example usage (uncomment and adapt with real data):
# x_train, x_test, y_train, y_test = your_data_loading_and_preprocessing()
# train_percent = 0.8  # example
# DB = "YourDatabaseName"
# metrics = proposed_model(x_train, x_test, y_train, y_test, train_percent, DB)
# print(metrics)
